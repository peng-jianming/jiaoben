<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>前端计算机视觉：OpenCV.js 图像处理演示</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdn.bootcdn.net/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <script async src="./opencv.js" onload="onOpenCvReady();"
        type="text/javascript"></script>
    <style>
        .canvas-container {
            display: flex;
            gap: 20px;
            justify-content: center;
            flex-wrap: wrap;
        }

        canvas {
            border: 1px solid #ccc;
            max-width: 100%;
            height: auto;
        }

        .control-panel {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .processing-btn {
            margin: 5px;
            padding: 8px 16px;
            border: none;
            border-radius: 4px;
            background: #007bff;
            color: white;
            cursor: pointer;
            transition: background 0.3s;
        }

        .processing-btn:hover {
            background: #0056b3;
        }

        .processing-btn.active {
            background: #28a745;
        }

        .video-container {
            display: flex;
            gap: 20px;
            justify-content: center;
            flex-wrap: wrap;
        }

        video,
        canvas {
            border: 1px solid #ccc;
            max-width: 100%;
        }
    </style>
</head>

<body class="bg-gray-50">
    <div class="container mx-auto px-4 py-8">
        <h1 class="text-3xl font-bold text-center mb-8 text-gray-800">
            <i class="fas fa-eye mr-2"></i>前端计算机视觉：OpenCV.js 图像处理演示
        </h1>

        <div id="status" class="text-center mb-4 p-4 bg-blue-100 text-blue-800 rounded">
            正在加载 OpenCV.js...
        </div>

        <!-- 图像处理部分 -->
        <div class="bg-white rounded-lg shadow-lg p-6 mb-8">
            <h2 class="text-2xl font-semibold mb-4 text-gray-700">
                <i class="fas fa-image mr-2"></i>图像处理
            </h2>

            <div class="mb-4">
                <input type="file" id="imageInput" accept="image/*"
                    class="block w-full text-sm text-gray-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-blue-50 file:text-blue-700 hover:file:bg-blue-100">
            </div>

            <div class="control-panel">
                <h3 class="text-lg font-semibold mb-3">处理选项</h3>
                <div class="flex flex-wrap gap-2">
                    <button class="processing-btn" onclick="convertToGray()">灰度转换</button>
                    <button class="processing-btn" onclick="applyGaussianBlur()">高斯模糊</button>
                    <button class="processing-btn" onclick="applyCanny()">Canny边缘检测</button>
                    <button class="processing-btn" onclick="applySobel()">Sobel边缘检测</button>
                    <button class="processing-btn" onclick="detectCorners()">角点检测</button>
                    <button class="processing-btn" onclick="applyThreshold()">阈值分割</button>
                    <button class="processing-btn" onclick="detectContours()">轮廓检测</button>
                    <button class="processing-btn" onclick="resetImage()">重置图像</button>
                </div>
            </div>

            <div class="canvas-container mt-4">
                <div>
                    <p class="text-center font-semibold mb-2">原始图像</p>
                    <canvas id="inputCanvas"></canvas>
                </div>
                <div>
                    <p class="text-center font-semibold mb-2">处理后图像</p>
                    <canvas id="outputCanvas"></canvas>
                </div>
            </div>
        </div>

        <!-- 实时视频处理部分 -->
        <div class="bg-white rounded-lg shadow-lg p-6">
            <h2 class="text-2xl font-semibold mb-4 text-gray-700">
                <i class="fas fa-video mr-2"></i>实时视频处理
            </h2>

            <div class="control-panel">
                <button id="startVideoBtn" class="processing-btn" onclick="startVideo()">
                    <i class="fas fa-play mr-1"></i>开始摄像头
                </button>
                <button id="stopVideoBtn" class="processing-btn" disabled onclick="stopVideo()">
                    <i class="fas fa-stop mr-1"></i>停止处理
                </button>
                <button id="faceDetectBtn" class="processing-btn" onclick="toggleFaceDetection()">
                    <i class="fas fa-user mr-1"></i>人脸检测
                </button>
            </div>

            <div class="video-container mt-4">
                <div>
                    <p class="text-center font-semibold mb-2">原始视频</p>
                    <video id="inputVideo" autoplay muted playsinline></video>
                </div>
                <div>
                    <p class="text-center font-semibold mb-2">处理后视频</p>
                    <canvas id="videoOutputCanvas"></canvas>
                </div>
            </div>
        </div>
    </div>

    <script>
        let src, dst, originalSrc;
        let inputCanvas, outputCanvas;
        let video, videoOutputCanvas, videoContext;
        let processing = false;
        let requestId;
        let faceCascade;
        let faceDetectionEnabled = false;
        let videoSrc, videoDst, videoGray;

        function onOpenCvReady() {
            document.getElementById('status').innerHTML = 'OpenCV.js 已加载完成 ✓';
            initializeElements();
            setupImageInput();
            // loadFaceDetectionModel();
        }

        function initializeElements() {
            inputCanvas = document.getElementById('inputCanvas');
            outputCanvas = document.getElementById('outputCanvas');
            video = document.getElementById('inputVideo');
            videoOutputCanvas = document.getElementById('videoOutputCanvas');
            videoContext = videoOutputCanvas.getContext('2d');
        }

        function setupImageInput() {
            const imageInput = document.getElementById('imageInput');
            imageInput.addEventListener('change', function (e) {
                const file = e.target.files[0];
                if (file) {
                    const reader = new FileReader();
                    reader.onload = function (event) {
                        const img = new Image();
                        img.onload = function () {
                            loadImageToCanvas(img);
                        };
                        img.src = reader.result;
                    };
                    reader.readAsDataURL(file);
                }
            });
        }

        function loadImageToCanvas(img) {
            inputCanvas.width = img.width;
            inputCanvas.height = img.height;
            outputCanvas.width = img.width;
            outputCanvas.height = img.height;

            src = cv.imread(img);
            originalSrc = src.clone();
            dst = new cv.Mat();

            cv.imshow(inputCanvas, src);
            src.copyTo(dst);
            cv.imshow(outputCanvas, dst);
        }

        function convertToGray() {
            if (!src) return;
            // 将原始图像从RGB颜色空间转换为灰度图像
            cv.cvtColor(originalSrc, dst, cv.COLOR_RGB2GRAY);
            // 再将灰度图像转换回RGB格式（以便后续显示和处理）
            // cv.cvtColor(dst, dst, cv.COLOR_GRAY2RGB);
            // 在输出画布上显示处理后的图像
            cv.imshow(outputCanvas, dst);
        }

        function applyGaussianBlur() {
            if (!src) return;
            let ksize = new cv.Size(15, 15);
            cv.GaussianBlur(originalSrc, dst, ksize, 0, 0, cv.BORDER_DEFAULT);
            cv.imshow(outputCanvas, dst);
        }

        function applyCanny() {
            if (!src) return;
            let gray = new cv.Mat();
            cv.cvtColor(originalSrc, gray, cv.COLOR_RGB2GRAY);
            cv.Canny(gray, dst, 100, 200, 3, false);
            cv.cvtColor(dst, dst, cv.COLOR_GRAY2RGB);
            cv.imshow(outputCanvas, dst);
            gray.delete();
        }

        function applySobel() {
            if (!src) return;
            let gray = new cv.Mat();
            let sobelx = new cv.Mat();
            let sobely = new cv.Mat();
            let abs_sobelx = new cv.Mat();
            let abs_sobely = new cv.Mat();

            cv.cvtColor(originalSrc, gray, cv.COLOR_RGB2GRAY);
            cv.Sobel(gray, sobelx, cv.CV_16S, 1, 0, 3, 1, 0, cv.BORDER_DEFAULT);
            cv.Sobel(gray, sobely, cv.CV_16S, 0, 1, 3, 1, 0, cv.BORDER_DEFAULT);
            cv.convertScaleAbs(sobelx, abs_sobelx);
            cv.convertScaleAbs(sobely, abs_sobely);
            cv.addWeighted(abs_sobelx, 0.5, abs_sobely, 0.5, 0, dst);
            cv.cvtColor(dst, dst, cv.COLOR_GRAY2RGB);
            cv.imshow(outputCanvas, dst);

            gray.delete(); sobelx.delete(); sobely.delete();
            abs_sobelx.delete(); abs_sobely.delete();
        }

        function detectCorners() {
            if (!src) return;
            let gray = new cv.Mat();
            let dstHarris = new cv.Mat();
            let dstNorm = new cv.Mat();
            let dstNormScaled = new cv.Mat();

            cv.cvtColor(originalSrc, gray, cv.COLOR_RGB2GRAY);
            cv.cornerHarris(gray, dstHarris, 2, 3, 0.04, cv.BORDER_DEFAULT);
            cv.normalize(dstHarris, dstNorm, 0, 255, cv.NORM_MINMAX, cv.CV_32FC1);
            cv.convertScaleAbs(dstNorm, dstNormScaled);

            originalSrc.copyTo(dst);
            for (let j = 0; j < dstNorm.rows; j += 4) {
                for (let i = 0; i < dstNorm.cols; i += 4) {
                    if (dstNorm.ucharAt(j, i) > 100) {
                        cv.circle(dst, new cv.Point(i, j), 3, [0, 255, 0, 255], 2);
                    }
                }
            }
            cv.imshow(outputCanvas, dst);

            gray.delete(); dstHarris.delete(); dstNorm.delete(); dstNormScaled.delete();
        }

        function applyThreshold() {
            if (!src) return;
            let gray = new cv.Mat();
            cv.cvtColor(originalSrc, gray, cv.COLOR_RGB2GRAY);
            cv.threshold(gray, dst, 127, 255, cv.THRESH_BINARY);
            cv.cvtColor(dst, dst, cv.COLOR_GRAY2RGB);
            cv.imshow(outputCanvas, dst);
            gray.delete();
        }

        function detectContours() {
            if (!src) return;
            let gray = new cv.Mat();
            let thresh = new cv.Mat();
            let contours = new cv.MatVector();
            let hierarchy = new cv.Mat();

            cv.cvtColor(originalSrc, gray, cv.COLOR_RGB2GRAY);
            cv.threshold(gray, thresh, 127, 255, cv.THRESH_BINARY);
            cv.findContours(thresh, contours, hierarchy, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE);

            originalSrc.copyTo(dst);
            for (let i = 0; i < contours.size(); i++) {
                let color = new cv.Scalar(Math.random() * 255, Math.random() * 255, Math.random() * 255);
                cv.drawContours(dst, contours, i, color, 2);
            }
            cv.imshow(outputCanvas, dst);

            gray.delete(); thresh.delete(); contours.delete(); hierarchy.delete();
        }

        function resetImage() {
            if (!originalSrc) return;
            originalSrc.copyTo(dst);
            cv.imshow(outputCanvas, dst);
        }

        // 视频处理功能
        function startVideo() {
            navigator.mediaDevices.getUserMedia({ video: true, audio: false })
                .then(function (stream) {
                    video.srcObject = stream;
                    video.onloadedmetadata = function (e) {
                        video.play();
                        startVideoProcessing();
                    };
                })
                .catch(function (err) {
                    console.error('摄像头访问错误: ' + err);
                    document.getElementById('status').innerHTML = '无法访问摄像头';
                });
        }

        function startVideoProcessing() {
            if (processing) return;

            videoOutputCanvas.width = video.videoWidth;
            videoOutputCanvas.height = video.videoHeight;

            videoSrc = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
            videoDst = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
            videoGray = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC1);

            processing = true;
            document.getElementById('startVideoBtn').disabled = true;
            document.getElementById('stopVideoBtn').disabled = false;

            processVideoFrame();
        }

        function stopVideo() {
            if (!processing) return;
            processing = false;

            document.getElementById('startVideoBtn').disabled = false;
            document.getElementById('stopVideoBtn').disabled = true;

            if (videoSrc) videoSrc.delete();
            if (videoDst) videoDst.delete();
            if (videoGray) videoGray.delete();

            if (requestId) {
                cancelAnimationFrame(requestId);
            }

            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
        }

        function processVideoFrame() {
            if (!processing) return;

            try {
                cv.imread(video, videoSrc);

                if (faceDetectionEnabled && faceCascade) {
                    processWithFaceDetection();
                } else {
                    // 默认处理：灰度转换
                    cv.cvtColor(videoSrc, videoGray, cv.COLOR_RGBA2GRAY);
                    cv.cvtColor(videoGray, videoDst, cv.COLOR_GRAY2RGBA);
                }

                cv.imshow(videoOutputCanvas, videoDst);
                requestId = requestAnimationFrame(processVideoFrame);
            } catch (err) {
                console.error('处理视频帧时出错:', err);
                stopVideo();
            }
        }

        function processWithFaceDetection() {
            cv.cvtColor(videoSrc, videoGray, cv.COLOR_RGBA2GRAY);
            let faces = new cv.RectVector();
            faceCascade.detectMultiScale(videoGray, faces, 1.1, 3, 0, new cv.Size(30, 30));

            videoSrc.copyTo(videoDst);
            for (let i = 0; i < faces.size(); i++) {
                let face = faces.get(i);
                let point1 = new cv.Point(face.x, face.y);
                let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                cv.rectangle(videoDst, point1, point2, [255, 0, 0, 255], 2);
            }
            faces.delete();
        }

        function toggleFaceDetection() {
            faceDetectionEnabled = !faceDetectionEnabled;
            const btn = document.getElementById('faceDetectBtn');
            if (faceDetectionEnabled) {
                btn.classList.add('active');
                btn.innerHTML = '<i class="fas fa-user mr-1"></i>关闭人脸检测';
            } else {
                btn.classList.remove('active');
                btn.innerHTML = '<i class="fas fa-user mr-1"></i>人脸检测';
            }
        }

        function loadFaceDetectionModel() {
            // 由于模型文件较大，这里简化处理
            // 实际应用中需要加载haarcascade_frontalface_default.xml
            console.log('人脸检测模型加载功能已准备（需要实际模型文件）');
        }

        // 清理资源
        window.addEventListener('beforeunload', function () {
            if (src) src.delete();
            if (dst) dst.delete();
            if (originalSrc) originalSrc.delete();
            if (videoSrc) videoSrc.delete();
            if (videoDst) videoDst.delete();
            if (videoGray) videoGray.delete();
        });
    </script>
</body>

</html>